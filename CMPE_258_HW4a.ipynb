{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMPE_258_HW4a.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anAY36qHSEUl"
      },
      "source": [
        "# Samer Baslan\n",
        "# CMPE-258: Deep Learning, Vijay Eranti\n",
        "# Spring 2021, SJSU\n",
        "# Homework 4 Part 1: MNIST classifier with various training knobs with Numpy\n",
        "\n",
        "\n",
        "Resources used:\n",
        "1. Grokking Deep Learning (Chapter 8)\n",
        "2. https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
        "\n",
        "\n",
        "Note: Some functionality (confusion matrix, update learning rate, show errors) was difficult to implement in this version because all the examples use models created in Keras and the fit/predict API. They will be implemented in part 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whtt6JTfS2lt"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZTUqs_wR_XM"
      },
      "source": [
        "import numpy as np\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LaCfG_FSuBq"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMYLGAsnSgwX"
      },
      "source": [
        "##Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t90vpyvpSPe4"
      },
      "source": [
        "#return x if x>0; 0 otherwise\n",
        "def relu(x):\n",
        "  return (x >= 0) * x \n",
        "\n",
        "#returns 1 for input > 0\n",
        "def relu2deriv(output):\n",
        "  return output >= 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRwKCCW0FeD_"
      },
      "source": [
        "def plot_confusion_matrix(true, pred):\n",
        "  cm = confusion_matrix(true, pred)\n",
        "  plt.imshow(cm, interpolation = \"nearest\", mcap = plt.cm.rainbow)\n",
        "  labels = range(10)\n",
        "  ticks = np.arange(len(labels))\n",
        "  plt.xticks(ticks, labels, rotation = 50)\n",
        "  plt.yticks(tick_marks, labels)\n",
        "  thresh = cm.max() / 2.0\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment = \"center\", color = \"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_rvVK-US7Jb"
      },
      "source": [
        "##Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwclZ9kXVbGN"
      },
      "source": [
        "batch_size = 100\n",
        "alpha, iterations = (0.001, 300)\n",
        "pixels_per_image, num_labels, hidden_size = (784, 10, 100)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulZd328bS-0H"
      },
      "source": [
        "##Load/Scale/Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1Pj3gMFVkY1",
        "outputId": "cb027d3a-67da-46e2-8375-c36e7e676837"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIOMCzKNFaXN",
        "outputId": "9b1845f4-5a3b-4104-deda-a7eb8a2f11ea"
      },
      "source": [
        "normalization_layer = preprocessing.Normalization()\n",
        "normalization_layer.adapt(X_train)\n",
        "normalization_layer(X_train)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(60000, 28, 28), dtype=float32, numpy=\n",
              "array([[[-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        ...,\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948]],\n",
              "\n",
              "       [[-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        ...,\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948]],\n",
              "\n",
              "       [[-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        ...,\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        ...,\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948]],\n",
              "\n",
              "       [[-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        ...,\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948]],\n",
              "\n",
              "       [[-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        ...,\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948],\n",
              "        [-0.00300378, -0.00990673, -0.02825189, ..., -0.06605659,\n",
              "         -0.02814181, -0.00788948]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hFDexynFaQP",
        "outputId": "4291b55f-ec14-4fee-cae3-238a2c7c2347"
      },
      "source": [
        "normalization_layer.adapt(X_test)\n",
        "normalization_layer(X_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10000, 28, 28), dtype=float32, numpy=\n",
              "array([[[-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        ...,\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782]],\n",
              "\n",
              "       [[-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        ...,\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782]],\n",
              "\n",
              "       [[-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        ...,\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        ...,\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782]],\n",
              "\n",
              "       [[-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        ...,\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782]],\n",
              "\n",
              "       [[-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        ...,\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782],\n",
              "        [-0.00329633, -0.01032096, -0.02632251, ..., -0.06433523,\n",
              "         -0.02871007, -0.00899782]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm2r_XJaVqFJ"
      },
      "source": [
        "images, labels = (X_train[0:1000].reshape(1000, 28*28) / 255, y_train[0:1000])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6pxanUmV4hW"
      },
      "source": [
        "one_hot_labels = np.zeros((len(labels), 10))\n",
        "for i, l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "\n",
        "labels = one_hot_labels #now labels is (1000, 10)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3So2JfIWLA8"
      },
      "source": [
        "test_images = X_test.reshape(len(X_test), 28*28) / 255\n",
        "test_labels = np.zeros((len(y_test), 10))\n",
        "\n",
        "for i, l in enumerate(y_test):\n",
        "  test_labels[i][l] = 1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp3YB53BJJOR"
      },
      "source": [
        "I found that using this structure gave me most consistent results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs_fPZcUW3qT"
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size * 2)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size * 2, 80)) - 0.1\n",
        "weights_2_3 = 0.2*np.random.random((80, num_labels)) - 0.1"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyxQLsyNDXeY"
      },
      "source": [
        "## 3 Layer Neural Network, RELU nonlinearity, no dropout (overfitting expected)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fxk71xkDWu-",
        "outputId": "899acdfb-e813-4abc-9b16-08323371057b"
      },
      "source": [
        "alpha, iterations, hidden_size = (0.005, 300, 100)\n",
        "pixels_per_image, num_labels = (784, 10)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size * 2)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size * 2, 80)) - 0.1\n",
        "weights_2_3 = 0.2*np.random.random((80, num_labels)) - 0.1\n",
        "\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0,0)\n",
        "    for i in range(len(images)):\n",
        "        layer_0 = images[i:i+1]\n",
        "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "        layer_2 = relu(np.dot(layer_1,weights_1_2))\n",
        "        layer_3 = np.dot(layer_2, weights_2_3)\n",
        "\n",
        "        error += np.sum((labels[i:i+1] - layer_3) ** 2)\n",
        "        correct_cnt += int(np.argmax(layer_3) == np.argmax(labels[i:i+1]))\n",
        "        layer_3_delta = (labels[i:i+1] - layer_3)\n",
        "        layer_2_delta = layer_3_delta.dot(weights_2_3.T) * relu2deriv(layer_2)\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "\n",
        "        weights_2_3 += alpha * layer_2.T.dot(layer_3_delta)\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    if(j%10 == 0):\n",
        "        test_error = 0.0\n",
        "        test_correct_cnt = 0\n",
        "\n",
        "        for i in range(len(test_images)):\n",
        "            layer_0 = test_images[i:i+1]\n",
        "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "            layer_2 = relu(np.dot(layer_1, weights_1_2))\n",
        "            layer_3 = np.dot(layer_2, weights_2_3)\n",
        "\n",
        "            test_error += np.sum((test_labels[i:i+1] - layer_3) ** 2)\n",
        "            test_correct_cnt += int(np.argmax(layer_3) == np.argmax(test_labels[i:i+1]))\n",
        "\n",
        "        sys.stdout.write(\"\\n\" + \\\n",
        "                         \"I:\" + str(j) + \\\n",
        "                         \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
        "                         \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
        "                         \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
        "                         \" Train-Acc:\" + str(correct_cnt/ float(len(images))))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I:0 Test-Err:0.588 Test-Acc:0.6518 Train-Err:0.705 Train-Acc:0.563\n",
            "I:10 Test-Err:0.369 Test-Acc:0.8405 Train-Err:0.240 Train-Acc:0.933\n",
            "I:20 Test-Err:0.355 Test-Acc:0.8493 Train-Err:0.179 Train-Acc:0.967\n",
            "I:30 Test-Err:0.358 Test-Acc:0.8408 Train-Err:0.148 Train-Acc:0.984\n",
            "I:40 Test-Err:0.367 Test-Acc:0.838 Train-Err:0.128 Train-Acc:0.99\n",
            "I:50 Test-Err:0.377 Test-Acc:0.8326 Train-Err:0.115 Train-Acc:0.994\n",
            "I:60 Test-Err:0.390 Test-Acc:0.8243 Train-Err:0.105 Train-Acc:0.996\n",
            "I:70 Test-Err:0.405 Test-Acc:0.8147 Train-Err:0.098 Train-Acc:0.998\n",
            "I:80 Test-Err:0.421 Test-Acc:0.8095 Train-Err:0.094 Train-Acc:0.998\n",
            "I:90 Test-Err:0.437 Test-Acc:0.8002 Train-Err:0.090 Train-Acc:0.998\n",
            "I:100 Test-Err:0.452 Test-Acc:0.793 Train-Err:0.087 Train-Acc:0.998\n",
            "I:110 Test-Err:0.467 Test-Acc:0.7879 Train-Err:0.084 Train-Acc:0.998\n",
            "I:120 Test-Err:0.482 Test-Acc:0.7828 Train-Err:0.082 Train-Acc:0.998\n",
            "I:130 Test-Err:0.493 Test-Acc:0.7786 Train-Err:0.080 Train-Acc:0.999\n",
            "I:140 Test-Err:0.502 Test-Acc:0.7745 Train-Err:0.078 Train-Acc:0.999\n",
            "I:150 Test-Err:0.510 Test-Acc:0.7725 Train-Err:0.077 Train-Acc:0.999\n",
            "I:160 Test-Err:0.516 Test-Acc:0.7691 Train-Err:0.076 Train-Acc:0.999\n",
            "I:170 Test-Err:0.522 Test-Acc:0.7659 Train-Err:0.075 Train-Acc:1.0\n",
            "I:180 Test-Err:0.528 Test-Acc:0.7624 Train-Err:0.074 Train-Acc:1.0\n",
            "I:190 Test-Err:0.535 Test-Acc:0.7591 Train-Err:0.073 Train-Acc:1.0\n",
            "I:200 Test-Err:0.543 Test-Acc:0.7555 Train-Err:0.073 Train-Acc:1.0\n",
            "I:210 Test-Err:0.552 Test-Acc:0.7526 Train-Err:0.073 Train-Acc:1.0\n",
            "I:220 Test-Err:0.564 Test-Acc:0.7483 Train-Err:0.073 Train-Acc:0.999\n",
            "I:230 Test-Err:0.576 Test-Acc:0.7451 Train-Err:0.073 Train-Acc:0.999\n",
            "I:240 Test-Err:0.585 Test-Acc:0.7416 Train-Err:0.073 Train-Acc:0.999\n",
            "I:250 Test-Err:0.596 Test-Acc:0.7377 Train-Err:0.073 Train-Acc:0.999\n",
            "I:260 Test-Err:0.604 Test-Acc:0.7359 Train-Err:0.073 Train-Acc:0.999\n",
            "I:270 Test-Err:0.611 Test-Acc:0.7329 Train-Err:0.074 Train-Acc:0.999\n",
            "I:280 Test-Err:0.612 Test-Acc:0.7302 Train-Err:0.074 Train-Acc:0.999\n",
            "I:290 Test-Err:0.607 Test-Acc:0.7305 Train-Err:0.075 Train-Acc:0.999"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhjf1wrYE5g0"
      },
      "source": [
        "##3 Layer Neural Network, RELU nonlinearity, with dropout to reduce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r8OMVAoh43c",
        "outputId": "91203fcd-c636-44df-9161-225b9173c9f6"
      },
      "source": [
        "alpha, iterations, hidden_size = (0.001, 160, 100)\n",
        "pixels_per_image, num_labels = (784, 10)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size * 2)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size * 2, 80)) - 0.1\n",
        "weights_2_3 = 0.2*np.random.random((80, num_labels)) - 0.1\n",
        "\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0,0)\n",
        "    for i in range(len(images)):\n",
        "        layer_0 = images[i:i+1]\n",
        "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "        dropout_mask_1 = np.random.randint(2, size = layer_1.shape)\n",
        "        layer_1 *= dropout_mask_1 * 2\n",
        "        layer_2 = relu(np.dot(layer_1,weights_1_2))\n",
        "        dropout_mask_2 = np.random.randint(2, size = layer_2.shape)\n",
        "        layer_2 *= dropout_mask_2 * 2\n",
        "        layer_3 = np.dot(layer_2, weights_2_3)\n",
        "\n",
        "        error += np.sum((labels[i:i+1] - layer_3) ** 2)\n",
        "        correct_cnt += int(np.argmax(layer_3) == np.argmax(labels[i:i+1]))\n",
        "        layer_3_delta = (labels[i:i+1] - layer_3)\n",
        "        layer_2_delta = layer_3_delta.dot(weights_2_3.T) * relu2deriv(layer_2)\n",
        "        layer_2_delta *= dropout_mask_2\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "        layer_1_delta *= dropout_mask_1\n",
        "\n",
        "        weights_2_3 += alpha * layer_2.T.dot(layer_3_delta)\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    if(j%10 == 0):\n",
        "        test_error = 0.0\n",
        "        test_correct_cnt = 0\n",
        "\n",
        "        for i in range(len(test_images)):\n",
        "            layer_0 = test_images[i:i+1]\n",
        "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "            layer_2 = relu(np.dot(layer_1, weights_1_2))\n",
        "            layer_3 = np.dot(layer_2, weights_2_3)\n",
        "\n",
        "            test_error += np.sum((test_labels[i:i+1] - layer_3) ** 2)\n",
        "            test_correct_cnt += int(np.argmax(layer_3) == np.argmax(test_labels[i:i+1]))\n",
        "\n",
        "        sys.stdout.write(\"\\n\" + \\\n",
        "                         \"I:\" + str(j) + \\\n",
        "                         \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
        "                         \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
        "                         \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
        "                         \" Train-Acc:\" + str(correct_cnt/ float(len(images))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I:0 Test-Err:0.885 Test-Acc:0.261 Train-Err:1.151 Train-Acc:0.103\n",
            "I:10 Test-Err:0.750 Test-Acc:0.6466 Train-Err:0.765 Train-Acc:0.47\n",
            "I:20 Test-Err:0.655 Test-Acc:0.7006 Train-Err:0.663 Train-Acc:0.585\n",
            "I:30 Test-Err:0.599 Test-Acc:0.7437 Train-Err:0.616 Train-Acc:0.618\n",
            "I:40 Test-Err:0.560 Test-Acc:0.7699 Train-Err:0.592 Train-Acc:0.636\n",
            "I:50 Test-Err:0.541 Test-Acc:0.7731 Train-Err:0.582 Train-Acc:0.647\n",
            "I:60 Test-Err:0.530 Test-Acc:0.7777 Train-Err:0.569 Train-Acc:0.672\n",
            "I:70 Test-Err:0.524 Test-Acc:0.7777 Train-Err:0.556 Train-Acc:0.681\n",
            "I:80 Test-Err:0.515 Test-Acc:0.7735 Train-Err:0.549 Train-Acc:0.711\n",
            "I:90 Test-Err:0.520 Test-Acc:0.778 Train-Err:0.559 Train-Acc:0.681\n",
            "I:100 Test-Err:0.518 Test-Acc:0.7701 Train-Err:0.550 Train-Acc:0.708\n",
            "I:110 Test-Err:0.514 Test-Acc:0.7785 Train-Err:0.573 Train-Acc:0.698\n",
            "I:120 Test-Err:0.508 Test-Acc:0.783 Train-Err:0.553 Train-Acc:0.698\n",
            "I:130 Test-Err:0.515 Test-Acc:0.7875 Train-Err:0.554 Train-Acc:0.685\n",
            "I:140 Test-Err:0.517 Test-Acc:0.8018 Train-Err:0.575 Train-Acc:0.66\n",
            "I:150 Test-Err:0.527 Test-Acc:0.7884 Train-Err:0.574 Train-Acc:0.676"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}